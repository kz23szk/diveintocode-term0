{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIF  WEEK2  授業課題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 主成分分析とは？\n",
    "\n",
    "データを人に説明するときを考えてみましょう。\n",
    "\n",
    "たとえばn次元のデータがあったとき、「特徴１のデータは〜、特徴２のデータは〜、...」のようにそれぞれ説明することはできます。\n",
    "しかし各特徴の傾向を説召したところで全体の特徴を言い表せたことにはなりませし、何より時間がかかります。\n",
    "このとき全体の特徴を言い表す尺度があれば「このデータ群は〇〇の尺度で表すとこんな傾向にあります。」と簡潔に説明することができます。\n",
    "\n",
    "このうまい尺度を見つける手法の一つが**主成分分析**と呼ばれる手法になります。\n",
    "\n",
    "主成分分析とはn次元データを少ない次元に縮め、データ全体を要約する手法です。\n",
    "注意すべきなのは次元縮めることは「それぞれの特徴を少しずつ集めて妥当な値を決めること」であり、いくつかの特徴を無視するわけではありません。\n",
    "\n",
    "主成分分析の具体的な方法を簡単に説明すると、\n",
    "\n",
    "1. もっともばらつき（分散）が大きい軸がそのデータの特徴を説明するのにふさわしい値とみなし、第一主成分とする。\n",
    "1. 第一主成分に直交する軸の中でもっとも分散が大きい軸を見つけ、それを第二主成分とする。\n",
    "1. 同様の手順で必要な第n-1主成分まで求める。\n",
    "\n",
    "となります。\n",
    "\n",
    "一般的には視覚的に見やすいため2,3次元に圧縮し、グラフ化することが多い。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 主成分分析の数式を用いた説明\n",
    "\n",
    "\n",
    "第一主成分を決める際、第一主成分の評価値を$Z$としたとき\n",
    "それぞれの特徴を加味した値にしたいため、\n",
    "それぞれの特徴にある重みをかけた和として表し、\n",
    "\n",
    "$$Z = a_1 x_1 + a_2 x_2 + \\cdots + a_n x_n$$\n",
    "\n",
    "とし、**「Zのばらつきが最も大きくなるような重み$\\vec{a} = (a_1, a_2, \\cdots, a_n)$が最も全体の特徴を捉えている」**と考え、\n",
    "この重み$\\vec{a} = (a_1, a_2, \\cdots, a_n)$を求める。ただし重みを自由に設定できると比較にならないため$\\|\\vec{a}\\|=1$という制約をつける。\n",
    "\n",
    "つまり主成分分析は「Zの分散が最大となる新しい評価軸の単位ベクトル（$\\vec{a}$）を見つけること」です。\n",
    "\n",
    "話を簡単にするために２次元ベクトルデータを１変数で説明する場合を数式を用いて説明します。\n",
    "\n",
    "ここで新しい座標軸の単位ベクトルを  $\\vec{a}=(a,ab)=(cosθ,sinθ)$ とする。\n",
    "まず、元の座標でデータの中心化を行い分散を求める。中心化とは、其々の軸の平均値に原点を移動する。分散とは、各データの値$(x_{1},x_{2},・・・ )$から全データの平均値$\\overline{x}$ を引いた値（偏）差の2乗の総和をデータの個数で割ったもの。従って、中心化させる事で各データの値がそのまま偏差となって計算が簡単になる。偏差の2乗を取るのは、原点を挟んでプラスとマイナスがあるので、相殺されるのを防ぐためである。\n",
    "そこで、ある点$k$(中心化後の座標を$x_{k}、y_{k}$とする）と新しい座標軸の単位ベクトルと内積を$D_{k}$とすると、$D_{k}＝ax_{k}＋by_{k} (a=cosθ、b=sinθ)$となる。その2乗は以下のようになる。\n",
    "$$\n",
    "(D_{k})^2＝(ax_{k}＋by_{k})^2 = a^2x_{k}^2+b^2y_{k}^2+2abx_{k}y_{k}\n",
    "$$\n",
    "分散（var）を求めるには、全てのデータの２乗の和を求めてデータの個数$（n）$で割ればいい。以下のように式が展開されるが、$a^2,b^2$は$(a,b)=(cosθ,sinθ)$ で定数であるため括り出せる。\n",
    "\n",
    "$$\n",
    "var=\\frac{1}{n}\\sum_{k=1}^{n}D_{k}^2 =\\frac{1}{n}\\sum_{k=1}^{n}(ax_{k}+by_{k})^2=\\frac{1}{n}\\sum_{k=1}^{n}(a^2x_{k}^2+b^2y_{k}+2abx_{k}y_{k})\n",
    "\\\\=a^2\\frac{1}{n}\\sum_{k=1}^{n}x_{k}^2+b^2\\frac{1}{n}\\sum_{k=1}^{n}y_{k}^2+2ab\\frac{1}{n}\\sum_{k=1}^{n}x_{k}y_{k} ・・・(A)\n",
    "$$\n",
    "(A)式のa、b以外のところはそれぞれ、回転前の座標軸のx座標の分散（中心化後なので平均0の分散）、y座標の分散、x座標y座標の共分散となっている。これを以下のように定める。\n",
    "$$\n",
    "\\frac{1}{n}\\sum_{k=1}^{n}x_{k}^2 => S_{x} : x座標の分散 \\\\\n",
    "\\frac{1}{n}\\sum_{k=1}^{n}y_{k}^2=> S_{y} : y座標の分散  \\\\\n",
    "\\frac{1}{n}\\sum_{k=1}^{n}x_{k}y_{k} => S_{xy} : x,y座標共分散\\\\\n",
    "$$\n",
    "また、$a＝cosθ、b＝sinθ$から、$a^2＋b^2＝1$の制約もある。\n",
    "この制約の中で、分散varの最大値を求めるために、ラグランジュの未定係数法を用いる。\n",
    "この方法によれば、以下のように関数を作り、Gの最大値を与える$a、b、\\lambda $を求めれば、Fの最大値を与える$a、b$も求まることが分かっている。\n",
    "\n",
    "$$\n",
    "F(a,b)=S_{x}a^2+S_{y}b^2+S_{xy}2ab\\\\\n",
    "C(a,b)=a^2+b^2-1=0\\\\\n",
    "G(a,b,\\lambda ) = F(a,b)-\\lambda C(a,b)\\\\\n",
    "$$\n",
    "これを解くには、$G$を$a、b、\\lambda $で其々偏微分して、＝0と置いた連立方程式を作る。\n",
    "\n",
    "$$\n",
    "G(a,b,\\lambda ) = F(a,b)-\\lambda C(a,b)=S_{x}a^2+S_{y}b^2+S_{xy}2ab-\\lambda (a^2+b^2-1)\\\\\n",
    "\\frac{∂G}{∂a}=2S_{x}a+2S_{xy}b-2\\lambda a=0\\\\\n",
    "\\frac{∂G}{∂b}=2S_{y}b+2S_{xy}a-2\\lambda b=0\\\\\n",
    "\\frac{∂G}{∂\\lambda }=-a^2-b^2+1=0\n",
    "$$\n",
    "\n",
    "上記の偏微分した式をまとめると\n",
    "$$\n",
    "S_{x}a+S_{xy}b=\\lambda a　・・・(1)  \\\\ \n",
    "S_{y}b+S_{xy}a=\\lambda b ・・・(2) \\\\\n",
    "a^2+b^2=1\\\\\n",
    "$$\n",
    "$$\n",
    "{\\begin{pmatrix}\n",
    "S_{x} &S_{xy} \\\\\n",
    "S_{xy} & S_{y} \n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "a \\\\\n",
    "b \\\\\n",
    "\\end{pmatrix}=\n",
    "}\n",
    "\\lambda \n",
    "\\begin{pmatrix}\n",
    "a \\\\\n",
    "b \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "この式は共分散行列\n",
    "\\begin{pmatrix}\n",
    "S_{x} &S_{xy} \\\\\n",
    "S_{xy} & S_{y} \n",
    "\\end{pmatrix}\n",
    "の固有方程式を求めることで解くことができる。\n",
    "\n",
    "以上から、$\\lambda$は共分散行列の固有値、(a、b)はその固有ベクトルになっているのでそれを求めればよい。\n",
    "固有ベクトルは通常、a、bの比しか求められないが、ここでは$a^2＋b^2＝1$の制約があるので、各固有値に対する$a、b$は一意に決まる。\n",
    "   \n",
    "分散varを最大化する$a、b、\\lambda$はラグランジュの未定係数法により、以下の(1)(2)のように求められた。(1)×a＋(2)×bと置くと、これも＝0となる。\n",
    "これを整理して、$a^2＋b^2＝1$の条件を使うと\n",
    "$$\n",
    "S_{x}a+S_{xy}b-\\lambda a=0　・・・(1)\\\\\n",
    "S_{y}b+S_{xy}a-\\lambda b=0　 ・・・(2)\\\\\n",
    "$$\n",
    "\n",
    "$(1) \\times a+(2) \\times b$は\n",
    "$$\n",
    "S_{x}a^2+S_{y}b^2+2S_{xy}ab-\\lambda (a^2+b^2)=0\\\\\n",
    "\\Leftrightarrow \n",
    "S_{x}a^2+S_{y}b^2+2S_{xy}ab=\\lambda \\\\\n",
    "$$\n",
    "となり、左辺は最大化を目指した主成分得点の分散varに他ならない。このvarの値は固有値$\\lambda $そのものであることを示してる。このように主成分分析は固有値問題に帰結することがわかる。\n",
    "\n",
    "各固有値の大きさが、その軸の主成分得点の分散の大きさを表す。それが大きいほど、全体のデータの特徴を、一方向からよく眺められることになり主成分分析の目的に合致する。\n",
    "\n",
    "固有値が大きい固有ベクトルから第１主成分、第2主成分、...の軸となる。\n",
    "\n",
    "対称行列の固有ベクトルは互いに直交するし、各ベクトルの長さは１となり、\n",
    "共分散行列は対称行列なので、それぞれの主成分軸は直交する。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pythonでの実装\n",
    "\n",
    "ここではpca_scratch（）関数を実装し、\n",
    "sklearnで用意されているPCAライブラリと同じ値をとるか確認する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "# 主成分分析をするライブラリ\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_scratch(data):\n",
    "    '''\n",
    "    自作の主成分分析を行う関数\n",
    "    n次元から2次元のデータにする。\n",
    "    引数：元データ　(n次元）行（データ数）列の行列\n",
    "    返り値：２次元に圧縮されたデータの　2行（データ数）列の行列\n",
    "    '''\n",
    "    # データの偏差を求める\n",
    "    data_deviation = np.array([row - np.mean(row)\n",
    "                               for row in X.transpose()]).transpose()\n",
    "    # 分散共分散行列を求める\n",
    "    cov_array = np.cov(data_deviation.T)\n",
    "    # cov関数を使わないなら下記のようになる\n",
    "    # X_bar = np.array([row - np.mean(row) for row in X.transpose()]).transpose()\n",
    "    # cov_array = np.dot(X_bar.T, X_bar) / (X.shape[0]-1)\n",
    "    print(\"スクラッチ分散共分散行列\")\n",
    "    print(cov_array)\n",
    "\n",
    "    # 上の分散共分散行列を用いて固有値、固有ベクトルを求める\n",
    "    lam, eigen_vecter = np.linalg.eig(cov_array)\n",
    "    print(\"スクラッチ固有値\")\n",
    "    print(lam)\n",
    "    print(\"スクラッチ固有ベクトル\")\n",
    "    print(eigen_vecter)\n",
    "\n",
    "    # np.linalg.eig関数では固有値順にソートされていないため\n",
    "    # 固有ベクトルを固有値の大きい順にならべかえる\n",
    "    lam_index = [n for n in range(len(lam))]\n",
    "    for i in range(len(lam)):\n",
    "        for j in range(i + 1, len(lam)):\n",
    "            if lam[i] < lam[j]:\n",
    "                lam[i], lam[j] = lam[j], lam[i]\n",
    "                lam_index[i], lam_index[j] = lam_index[j], lam_index[i]\n",
    "\n",
    "    print(\"スクラッチ第一主成分の寄与率\")\n",
    "    print(lam[0] / sum(lam))\n",
    "\n",
    "    # 各データの第一主成分の値を計算\n",
    "    first_axes = np.dot(eigen_vecter[:, lam_index[0]].T, data.T)\n",
    "    # 各データの第二主成分の値を計算\n",
    "    second_axes = np.dot(eigen_vecter[:, lam_index[1]].T, data.T)\n",
    "\n",
    "    return np.array([first_axes, second_axes])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[420748.          70137.5        199897.5       ]\n",
      " [ 70137.5        120686.11111111  92822.22222222]\n",
      " [199897.5         92822.22222222 141894.44444444]]\n",
      "ライブラリ固有値ベクトル\n",
      "[[ 0.8497074   0.23978088  0.4695769 ]\n",
      " [-0.42326275  0.84127071  0.33632161]]\n",
      "ライブラリ分散共分散行列\n",
      "[[420748.          70137.5        199897.5       ]\n",
      " [ 70137.5        120686.11111111  92822.22222222]\n",
      " [199897.5         92822.22222222 141894.44444444]]\n",
      "ライブラリ累積寄与率\n",
      "[0.80636224 0.17927921]\n",
      "############\n",
      "スクラッチ分散共分散行列\n",
      "[[420748.          70137.5        199897.5       ]\n",
      " [ 70137.5        120686.11111111  92822.22222222]\n",
      " [199897.5         92822.22222222 141894.44444444]]\n",
      "スクラッチ固有値\n",
      "[551010.34761483 122506.60493504   9811.60300569]\n",
      "スクラッチ固有ベクトル\n",
      "[[-0.8497074  -0.42326275 -0.3143978 ]\n",
      " [-0.23978088  0.84127071 -0.48452938]\n",
      " [-0.4695769   0.33632161  0.81632426]]\n",
      "スクラッチ第一主成分の寄与率\n",
      "0.8063622442455204\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1c93eb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PCAを使ったお手本コード\n",
    "# [Pythonのコードのスター総数， Javaのコードのスターの総数, 年収]\n",
    "X = np.array([[70, 30, 700],[32, 60, 480],[32, 20, 300],[20, 120, 600],[40, 120, 630], [40, 30, 520], [300, 1100, 1200], [2000, 400, 1500],[40, 180, 800]])\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(X)\n",
    "\n",
    "# データの確認\n",
    "print(\"ライブラリ固有値ベクトル\")\n",
    "print(pca.components_)\n",
    "print(\"ライブラリ分散共分散行列\")\n",
    "print(pca.get_covariance())\n",
    "print(\"ライブラリ累積寄与率\")\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "print(\"############\")\n",
    "\n",
    "# 次元削減をXに適用する．\n",
    "pca_point = pca.transform(X)\n",
    "\n",
    "# スクラッチ関数で圧縮したデータも用意する\n",
    "pca_point2 = pca_scratch(X)\n",
    "\n",
    "# スクラッチ関数で作った圧縮データは青でライブラリ関数で作った圧縮データは赤でプロットして結果を確認する\n",
    "plt.scatter(*pca_point.T,  color='red')\n",
    "plt.scatter(pca_point2[0], pca_point2[1],  color='blue')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## その他授業で学んだこと\n",
    "\n",
    "- sklearnのPCAがSVDなる類似手法であること\n",
    "    - 上記のプロット図にあるように左右対称になるケースがある。\n",
    "- ベイズの定理の応用例（ナイーブベイズフィルタ）\n",
    "- 形態素解析ライブラリ(MeCab)の使い方"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
