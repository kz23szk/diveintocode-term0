{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIF  WEEK2  授業課題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 主成分分析とは？\n",
    "\n",
    "データを人に説明するときを考えてみましょう。\n",
    "\n",
    "たとえばn次元のデータがあったとき、「特徴１のデータは〜、特徴２のデータは〜、...」のようにそれぞれ説明することはできます。\n",
    "しかし各特徴の傾向を説明したところで全体の特徴を言い表せたことにはなりませし、何より時間がかかります。\n",
    "このとき全体の特徴を言い表す尺度があれば「このデータ群は〇〇の尺度で表すとこんな傾向にあります。」と簡潔に説明することができます。\n",
    "\n",
    "このうまい尺度を見つける手法の一つが**主成分分析**と呼ばれる手法になります。\n",
    "\n",
    "主成分分析とはn次元データを少ない次元に縮め、データ全体を要約する手法です。\n",
    "注意すべきなのは次元縮めることは「それぞれの特徴を少しずつ集めて妥当な値を決めること」であり、いくつかの特徴を無視するわけではありません。\n",
    "\n",
    "つまり、それぞれのパラメータxに重みaをかけた評価値Zを\n",
    "$$Z = a_1 x_1 + a_2 x_2 + \\cdots + a_n x_n$$\n",
    "と表し、この重みaを求めることになります。\n",
    "\n",
    "ここでどんな$a_i$をとっても良いわけではなくaは必ず大きさが1となるように、つまりaは単位ベクトルになる必要があります。\n",
    "\n",
    "こうすることで評価値Zはxとaの内積となり、aが単位ベクトルであるとき、**内積の値は軸aにxを直行射影したときの長さ**に相当します。\n",
    "\n",
    "この長さの分散が最大になるようなaがもっともそれぞれの特徴を加味しつつ、なおかつ評価がばらついているため情報が残っているといえます。\n",
    "反対に分散が小さい場合は各データが共通してもっている特徴であり、どのデータでも変わらないため評価値Zとしてふさわしくありません。\n",
    "\n",
    "ここでaが単位ベクトルであることが生きてきます。各ベクトルaの長さがバラバラだとそこに直行射影したときの値は純粋な各データの長さではなくなるため、公平に分散の比較ができません。\n",
    "\n",
    "そのため**軸となるベクトルaは単位ベクトルである**という条件を設け、その中でZの分散が最大となるaを求めるのです。\n",
    "\n",
    "\n",
    "詳しくは次の項目で説明しますが、このようなベクトルaを求めるのに固有ベクトルが活躍します。\n",
    "この固有ベクトルは評価値Zの分散が最大となるような大きさ1のaとなるため、\n",
    "評価値Zを表す重みとして妥当な重みベクトルになります。\n",
    "\n",
    "長くなりましたが、主成分分析の具体的な方法を簡単に説明すると、\n",
    "\n",
    "1. もっともばらつき（分散）が大きい軸がそのデータの特徴を説明するのにふさわしい値とみなし、第一主成分とする。\n",
    "1. 第一主成分に直交する軸の中でもっとも分散が大きい軸を見つけ、それを第二主成分とする。\n",
    "1. 同様の手順で必要な第n-1主成分まで求める。\n",
    "\n",
    "となります。\n",
    "\n",
    "\n",
    "\n",
    "一般的にはグラフ化して説明することが多いため、2,3次元（第３主成分まで特定する）に圧縮することが多いです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 主成分分析の数式を用いた説明\n",
    "\n",
    "\n",
    "第一主成分を決める際、第一主成分の評価値を$Z$としたとき\n",
    "それぞれの特徴を加味した値が欲しいため、\n",
    "それぞれの特徴にある重みをかけた和として表し下記のようになります。\n",
    "\n",
    "$$Z = a_1 x_1 + a_2 x_2 + \\cdots + a_n x_n$$\n",
    "\n",
    "このとき、**「Zのばらつきが最も大きくなるような重み$\\vec{a} = (a_1, a_2, \\cdots, a_n)$が最も全体の特徴を捉えている」(★)**と考え、\n",
    "この重み$\\vec{a} = (a_1, a_2, \\cdots, a_n)$を求めます。ただし重みを自由に設定できると比較にならないため$\\|\\vec{a}\\|=1$という制約をつけます。\n",
    "\n",
    "つまり主成分分析は「Zの分散が最大となる新しい評価軸の単位ベクトル（$\\vec{a}$）を見つけること」です。\n",
    "\n",
    "話を簡単にするために２次元ベクトルデータを１変数で説明する場合を数式を用いて説明します。\n",
    "\n",
    "ここで新しい座標軸の単位ベクトルを  $\\vec{a}=(a,ab)=(cosθ,sinθ)$ とします。\n",
    "まず、元の座標でデータの中心化を行い分散を求めます。\n",
    "\n",
    "中心化とは、其々の軸の平均値に原点を移動します。\n",
    "\n",
    "分散とは、各データの値$(x_{1},x_{2},・・・ )$から全データの平均値$\\overline{x}$ を引いた値（偏）差の2乗の総和をデータの個数で割ったものです。\n",
    "\n",
    "従って、中心化させる事で各データの値がそのまま偏差となって計算が簡単になります。\n",
    "偏差の2乗を取るのは、原点を挟んでプラスとマイナスがあるので、相殺されるのを防ぐためです。\n",
    "\n",
    "そこで、ある点$k$(中心化後の座標を$x_{k}、y_{k}$とする）と新しい座標軸の単位ベクトルと内積を$D_{k}$とすると、$D_{k}＝ax_{k}＋by_{k} (a=cosθ、b=sinθ)$となる。その2乗は以下のようになります。\n",
    "$$\n",
    "(D_{k})^2＝(ax_{k}＋by_{k})^2 = a^2x_{k}^2+b^2y_{k}^2+2abx_{k}y_{k}\n",
    "$$\n",
    "分散（var）を求めるには、全てのデータの２乗の和を求めてデータの個数$（n）$で割ればよいです。以下のように式が展開されるが、$a^2,b^2$は$(a,b)=(cosθ,sinθ)$ で定数であるため括り出せます。\n",
    "\n",
    "$$\n",
    "var=\\frac{1}{n}\\sum_{k=1}^{n}D_{k}^2 =\\frac{1}{n}\\sum_{k=1}^{n}(ax_{k}+by_{k})^2=\\frac{1}{n}\\sum_{k=1}^{n}(a^2x_{k}^2+b^2y_{k}+2abx_{k}y_{k})\n",
    "\\\\=a^2\\frac{1}{n}\\sum_{k=1}^{n}x_{k}^2+b^2\\frac{1}{n}\\sum_{k=1}^{n}y_{k}^2+2ab\\frac{1}{n}\\sum_{k=1}^{n}x_{k}y_{k} ・・・(A)\n",
    "$$\n",
    "(A)式のa、b以外のところはそれぞれ、回転前の座標軸のx座標の分散（中心化後なので平均0の分散）、y座標の分散、x座標y座標の共分散となっています。これを以下のように定めます。\n",
    "$$\n",
    "\\frac{1}{n}\\sum_{k=1}^{n}x_{k}^2 => S_{x} : x座標の分散 \\\\\n",
    "\\frac{1}{n}\\sum_{k=1}^{n}y_{k}^2=> S_{y} : y座標の分散  \\\\\n",
    "\\frac{1}{n}\\sum_{k=1}^{n}x_{k}y_{k} => S_{xy} : x,y座標共分散\\\\\n",
    "$$\n",
    "また、$a＝cosθ、b＝sinθ$から、$a^2＋b^2＝1$の制約もある。\n",
    "この制約の中で、分散varの最大値を求めるために、ラグランジュの未定係数法を用います。\n",
    "この方法によれば、以下のように関数を作り、Gの最大値を与える$a、b、\\lambda $を求めれば、Fの最大値を与える$a、b$も求まることが分かります。\n",
    "\n",
    "$$\n",
    "F(a,b)=S_{x}a^2+S_{y}b^2+S_{xy}2ab\\\\\n",
    "C(a,b)=a^2+b^2-1=0\\\\\n",
    "G(a,b,\\lambda ) = F(a,b)-\\lambda C(a,b)\\\\\n",
    "$$\n",
    "これを解くには、$G$を$a、b、\\lambda $で其々偏微分して、＝0と置いた連立方程式を作ります。\n",
    "\n",
    "$$\n",
    "G(a,b,\\lambda ) = F(a,b)-\\lambda C(a,b)=S_{x}a^2+S_{y}b^2+S_{xy}2ab-\\lambda (a^2+b^2-1)\\\\\n",
    "\\frac{∂G}{∂a}=2S_{x}a+2S_{xy}b-2\\lambda a=0\\\\\n",
    "\\frac{∂G}{∂b}=2S_{y}b+2S_{xy}a-2\\lambda b=0\\\\\n",
    "\\frac{∂G}{∂\\lambda }=-a^2-b^2+1=0\n",
    "$$\n",
    "\n",
    "上記の偏微分した式をまとめると\n",
    "$$\n",
    "S_{x}a+S_{xy}b=\\lambda a　・・・(1)  \\\\ \n",
    "S_{y}b+S_{xy}a=\\lambda b ・・・(2) \\\\\n",
    "a^2+b^2=1\\\\\n",
    "$$\n",
    "$$\n",
    "{\\begin{pmatrix}\n",
    "S_{x} &S_{xy} \\\\\n",
    "S_{xy} & S_{y} \n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "a \\\\\n",
    "b \\\\\n",
    "\\end{pmatrix}=\n",
    "}\n",
    "\\lambda \n",
    "\\begin{pmatrix}\n",
    "a \\\\\n",
    "b \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "となり、この式は共分散行列\n",
    "\\begin{pmatrix}\n",
    "S_{x} &S_{xy} \\\\\n",
    "S_{xy} & S_{y} \n",
    "\\end{pmatrix}\n",
    "の固有方程式を求めることで解くことができます。\n",
    "\n",
    "以上から、$\\lambda$は共分散行列の固有値、(a、b)はその固有ベクトルになっているのでそれを求めれば良いことが分かります。\n",
    "固有ベクトルは通常、a、bの比しか求められないが、ここでは$a^2＋b^2＝1$の制約があるので、各固有値に対する$a、b$は一意に決まります。\n",
    "   \n",
    "分散varを最大化する$a、b、\\lambda$はラグランジュの未定係数法により、以下の(1)(2)のように求められます。(1)×a＋(2)×bと置くと、これも＝0となります。\n",
    "これを整理して、$a^2＋b^2＝1$の条件を使うと\n",
    "$$\n",
    "S_{x}a+S_{xy}b-\\lambda a=0　・・・(1)\\\\\n",
    "S_{y}b+S_{xy}a-\\lambda b=0　 ・・・(2)\\\\\n",
    "$$\n",
    "\n",
    "$(1) \\times a+(2) \\times b$は\n",
    "$$\n",
    "S_{x}a^2+S_{y}b^2+2S_{xy}ab-\\lambda (a^2+b^2)=0\\\\\n",
    "\\Leftrightarrow \n",
    "S_{x}a^2+S_{y}b^2+2S_{xy}ab=\\lambda \\\\\n",
    "$$\n",
    "となり、左辺はまさに最大化を目指した主成分得点の分散varです。このvarの値は固有値$\\lambda $そのものです。\n",
    "長くなりましたが、主成分分析は**固有値問題に帰結すること**がわかります。\n",
    "\n",
    "各固有値の大きさが、その軸の主成分得点の分散の大きさを表します。分散が大きいほど、★の目的と合致するため、\n",
    "求めた固有値が大きい固有ベクトルから第１主成分、第2主成分、...の軸（単位ベクトル）となります。\n",
    "\n",
    "対称行列の固有ベクトルの特徴として、それぞれの固有ベクトルは互いに直交し、各ベクトルの長さは１となります。\n",
    "共分散行列は対称行列なので、それぞれの主成分軸は直交します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pythonでの実装\n",
    "\n",
    "ここではpca_scratch（）関数を実装し、\n",
    "sklearnで用意されているPCAライブラリと同じ値をとるか確認します。\n",
    "\n",
    "※PCAライブラリのコードとデータセットは下記の記事から引用しています。\n",
    "[意味がわかる主成分分析](https://qiita.com/NoriakiOshita/items/460247bb57c22973a5f0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# 主成分分析をするライブラリ\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_scratch(data):\n",
    "    '''\n",
    "    自作の主成分分析を行う関数\n",
    "    n次元から2次元のデータにする。\n",
    "    引数：元データ　(n次元）行（データ数）列の行列\n",
    "    返り値：２次元に圧縮されたデータの　2行（データ数）列の行列\n",
    "    '''\n",
    "    \n",
    "    # 分散共分散行列を求める\n",
    "    # cov_array = np.cov(data, rowvar=0, bias=0)\n",
    "    # cov関数を使わないなら下記のようになる\n",
    "    X_bar = X - np.mean(data, axis=0)\n",
    "    cov_array = np.dot(X_bar.T, X_bar) / (X.shape[0] -1)\n",
    "    print(\"スクラッチ分散共分散行列\")\n",
    "    print(cov_array)\n",
    "\n",
    "    # 上の分散共分散行列を用いて固有値、固有ベクトルを求める\n",
    "    lam, eigen_vecter = np.linalg.eig(cov_array)\n",
    "    print(\"スクラッチ固有値\")\n",
    "    print(lam)\n",
    "    print(\"スクラッチ固有ベクトル\")\n",
    "    print(eigen_vecter)\n",
    "\n",
    "    # np.linalg.eig関数では固有値順にソートされていないため\n",
    "    # 固有ベクトルを固有値の大きい順にならべかえる\n",
    "    lam_index = [n for n in range(len(lam))]\n",
    "    for i in range(len(lam)):\n",
    "        for j in range(i + 1, len(lam)):\n",
    "            if lam[i] < lam[j]:\n",
    "                lam[i], lam[j] = lam[j], lam[i]\n",
    "                lam_index[i], lam_index[j] = lam_index[j], lam_index[i]\n",
    "\n",
    "    print(\"スクラッチ第一主成分の寄与率\")\n",
    "    print(lam[0] / sum(lam))\n",
    "\n",
    "    # 各データの第一主成分の値を計算\n",
    "    first_axes = np.dot(eigen_vecter[:, lam_index[0]].T, data.T)\n",
    "    # 各データの第二主成分の値を計算\n",
    "    second_axes = np.dot(eigen_vecter[:, lam_index[1]].T, data.T)\n",
    "\n",
    "    return np.array([first_axes, second_axes])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ライブラリ固有値ベクトル\n",
      "[[ 0.8497074   0.23978088  0.4695769 ]\n",
      " [-0.42326275  0.84127071  0.33632161]]\n",
      "ライブラリ分散共分散行列\n",
      "[[ 420748.           70137.5         199897.5       ]\n",
      " [  70137.5         120686.11111111   92822.22222222]\n",
      " [ 199897.5          92822.22222222  141894.44444444]]\n",
      "ライブラリ累積寄与率\n",
      "[ 0.80636224  0.17927921]\n",
      "############\n",
      "スクラッチ分散共分散行列\n",
      "[[ 420748.           70137.5         199897.5       ]\n",
      " [  70137.5         120686.11111111   92822.22222222]\n",
      " [ 199897.5          92822.22222222  141894.44444444]]\n",
      "スクラッチ固有値\n",
      "[ 551010.34761483  122506.60493504    9811.60300569]\n",
      "スクラッチ固有ベクトル\n",
      "[[-0.8497074  -0.42326275 -0.3143978 ]\n",
      " [-0.23978088  0.84127071 -0.48452938]\n",
      " [-0.4695769   0.33632161  0.81632426]]\n",
      "スクラッチ第一主成分の寄与率\n",
      "0.806362244246\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a160d1278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PCAを使ったお手本コード\n",
    "# [Pythonのコードのスター総数， Javaのコードのスターの総数, 年収]\n",
    "X = np.array([[70, 30, 700],[32, 60, 480],[32, 20, 300],[20, 120, 600],[40, 120, 630], [40, 30, 520], [300, 1100, 1200], [2000, 400, 1500],[40, 180, 800]])\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(X)\n",
    "\n",
    "# データの確認\n",
    "print(\"ライブラリ固有値ベクトル\")\n",
    "print(pca.components_)\n",
    "print(\"ライブラリ分散共分散行列\")\n",
    "print(pca.get_covariance())\n",
    "print(\"ライブラリ累積寄与率\")\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "print(\"############\")\n",
    "\n",
    "# 次元削減をXに適用する．\n",
    "pca_point = pca.transform(X)\n",
    "\n",
    "# スクラッチ関数で圧縮したデータも用意する\n",
    "pca_point2 = pca_scratch(X)\n",
    "\n",
    "# スクラッチ関数で作った圧縮データは青でライブラリ関数で作った圧縮データは赤でプロットして結果を確認する\n",
    "plt.scatter(*pca_point.T,  color='red')\n",
    "# plt.scatter(*pca_point,  color='green')\n",
    "plt.scatter(pca_point2[0], pca_point2[1],  color='blue')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## その他授業で学んだこと\n",
    "\n",
    "- sklearnのPCAがSVDなる類似手法であること\n",
    "    - 上記のプロット図にあるように左右対称になるケースがある。\n",
    "- ベイズの定理の応用例（ナイーブベイズフィルタ）\n",
    "- 形態素解析ライブラリ(MeCab)の使い方"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
